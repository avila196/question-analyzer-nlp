{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database creation and cleaning for Stack Overflow dataset\n",
    "#### The current notebook needs the \"posts_stackoverflow.xml\" file inside the raw_dataset folder in order to run properly.\n",
    "The dataset is read, parsed and exported into three CSV files (train, validation and test).\n",
    "It labels the questions based on their \"score\" property between 1 (good) and 0 (bad) question. These labels are calculated given the median score of all questions considered for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RyrEABkMI5C"
   },
   "outputs": [],
   "source": [
    "# INSTALL LIBRARIES AND DOWNLOAD FILES\n",
    "# !pip install py7zr\n",
    "# !wget https://archive.org/download/stackexchange/electronics.stackexchange.com.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dfa1etblLZux"
   },
   "outputs": [],
   "source": [
    "# UNZIP FILE\n",
    "'''\n",
    "import py7zr\n",
    "print(py7zr.__version__)\n",
    "import py7zr\n",
    "with py7zr.SevenZipFile('/content/electronics.7z', mode='r') as z:\n",
    "    z.extractall(\"/content/data\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "K5kNMzmR4I2a"
   },
   "outputs": [],
   "source": [
    "#Parse XML to CSV (cleaning data)\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iE4x0UJ34PgX"
   },
   "outputs": [],
   "source": [
    "#Class to hold all scores in the dataset\n",
    "class Scores:\n",
    "    def __init__(self):\n",
    "        #Array of all scores\n",
    "        self.scores_list = []\n",
    "        self.median = None\n",
    "\n",
    "    def append(self, score):\n",
    "        #append question to dictionary\n",
    "        self.scores_list.append(score)\n",
    "        \n",
    "    def process(self):\n",
    "        # orders scores and find median\n",
    "        # call before trying to score something\n",
    "        self.scores_list.sort()\n",
    "        self.median = self.scores_list[len(self.scores_list)//2]\n",
    "        \n",
    "    #Function that returns the label given the num of likes\n",
    "    def get_label(self, likes):\n",
    "        return 0 if likes <= self.median else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "880YJ1JS4SP6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "12000000\n",
      "12000000\n",
      "12000000\n",
      "13000000\n",
      "13000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "Processing scores...\n"
     ]
    }
   ],
   "source": [
    "#Create Scores objects based on all questions in the dataset\n",
    "data_size = 20094655\n",
    "scores = {str(year):Scores() for year in range(2010,2019+1)}\n",
    "i = 0\n",
    "for event, elem in ET.iterparse(\"../raw_dataset/posts_stackoverflow.xml\"):\n",
    "    #Add score if type is question\n",
    "    if elem.tag == \"row\" and event == \"end\" and elem.attrib[\"PostTypeId\"] == \"1\":\n",
    "        year = str(elem.attrib[\"CreationDate\"]).split(\"T\")[0].split(\"-\")[0]\n",
    "        if int(year)>=2020:\n",
    "            break\n",
    "        if int(year)>=2010:\n",
    "            scores[year].append(int(elem.attrib[\"Score\"]))\n",
    "            i += 1\n",
    "    elem.clear()\n",
    "    if i % 1000000 == 0 and i>0:\n",
    "        print(i)\n",
    "    if i == data_size:\n",
    "        break\n",
    "        \n",
    "print(\"Processing scores...\")\n",
    "for scorer in scores.values():\n",
    "    scorer.process()\n",
    "\n",
    "#for scorer in scores.values():\n",
    "#    scorer.process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XMQyI7CtgVGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "0\n",
      "900000\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "data_size = 18050016\n",
    "data_split = 1000000\n",
    "\n",
    "idx_val = set(random.sample(range(data_split),int(data_split*0.05)))\n",
    "idx_test = set()\n",
    "for i in range(int(data_split*0.05)):\n",
    "    n = random.randint(0, data_split-1)\n",
    "    while n in idx_val or n in idx_test:\n",
    "        n = random.randint(0, data_split-1)\n",
    "    idx_test.add(n)\n",
    "print(len(idx_test))\n",
    "print(len(idx_val))\n",
    "print(len(idx_test.intersection(idx_val)))\n",
    "z = np.zeros(data_split)\n",
    "z[list(idx_test)] = 1\n",
    "z[list(idx_val)] = 2\n",
    "print(np.count_nonzero(z == 0))\n",
    "print(np.count_nonzero(z == 1))\n",
    "print(np.count_nonzero(z == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "tpkp1ks7Gg-L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "1000000\n",
      "2000000\n",
      "2000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "4000000\n",
      "4000000\n",
      "5000000\n",
      "5000000\n",
      "6000000\n",
      "6000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "8000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "11000000\n",
      "11000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "13000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "18000000\n"
     ]
    }
   ],
   "source": [
    "#Parse XML to CSV (cleaning data)\n",
    "\n",
    "#Creates list of tags given the string\n",
    "def createTags(tags):\n",
    "    return \"|\".join(tags[1:-1].split(\"><\"))\n",
    "\n",
    "#Clean sentence (remove non alpha chars)\n",
    "def cleanSentence(sentence):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    sentence = p.sub('', sentence) \n",
    "    sentence = ''.join([(i.lower() if i.isalpha() else \" \") for i in sentence if i.isalpha() or i == \" \" or i == \"-\"])\n",
    "    return sentence\n",
    "    \n",
    "#Opens CSV file to write parsed rows\n",
    "i, j = 0, 0\n",
    "with open('../processed_files/data_stackoverflow_train.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file:\n",
    "    with open('../processed_files/data_stackoverflow_test.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_test:\n",
    "        with open('../processed_files/data_stackoverflow_val.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_val:\n",
    "            #Headers for train\n",
    "            data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            data_writer.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "            #Headers for test\n",
    "            data_writer_test = csv.writer(data_file_test, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            data_writer_test.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "            #Headers for val\n",
    "            data_writer_val = csv.writer(data_file_val, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            data_writer_val.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "            #Loop to iterate through every element on the XML file\n",
    "            for event, elem in ET.iterparse(\"../raw_dataset/posts_stackoverflow.xml\"):\n",
    "                #Write row if tag is row and post type is 1 (meaning it is a question)\n",
    "                if elem.tag == \"row\" and event == \"end\" and elem.attrib[\"PostTypeId\"] == \"1\":\n",
    "                    year = str(elem.attrib[\"CreationDate\"]).split(\"T\")[0].split(\"-\")[0]\n",
    "                    if int(year)>=2020:\n",
    "                        break\n",
    "                    if int(year)>=2010:\n",
    "                        if i % (data_size//data_split) == 0:\n",
    "                            score = int(elem.attrib[\"Score\"])\n",
    "                            if j in idx_test:\n",
    "                                data_writer_test.writerow([scores[year].get_label(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])\n",
    "                            elif j in idx_val:\n",
    "                                data_writer_val.writerow([scores[year].get_label(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])\n",
    "                            else:\n",
    "                                data_writer.writerow([scores[year].get_label(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])  \n",
    "                            j += 1\n",
    "                    i += 1\n",
    "                elem.clear()\n",
    "                if i % 1000000 == 0:\n",
    "                    print(i)\n",
    "                if j == data_split:\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "Xg7irEE_UX8v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trues over all on training: 0.41385\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "total_true = 0\n",
    "with open(\"../processed_files/data_stackoverflow_train.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        total_true += int(row[\"stars\"])\n",
    "\n",
    "print(\"trues over all on training:\", total_true/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trues over all on test: 0.41318\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "total_true = 0\n",
    "with open(\"../processed_files/data_stackoverflow_test.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        total_true += int(row[\"stars\"])\n",
    "\n",
    "print(\"trues over all on test:\", total_true/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QaxRuVxIfgL"
   },
   "source": [
    "# New section"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "database_creation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
