{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-RyrEABkMI5C"
   },
   "outputs": [],
   "source": [
    "# INSTALL LIBRARIES AND DOWNLOAD FILES\n",
    "# !pip install py7zr\n",
    "# !wget https://archive.org/download/stackexchange/electronics.stackexchange.com.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dfa1etblLZux"
   },
   "outputs": [],
   "source": [
    "# UNZIP FILE\n",
    "'''\n",
    "import py7zr\n",
    "print(py7zr.__version__)\n",
    "import py7zr\n",
    "with py7zr.SevenZipFile('/content/electronics.7z', mode='r') as z:\n",
    "    z.extractall(\"/content/data\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K5kNMzmR4I2a"
   },
   "outputs": [],
   "source": [
    "#Parse XML to CSV (cleaning data)\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iE4x0UJ34PgX"
   },
   "outputs": [],
   "source": [
    "#Find stars for given score\n",
    "class Scores:\n",
    "    def __init__(self):\n",
    "        #------------------------------\n",
    "        self.min_star = 0.5\n",
    "        self.max_star = 5.5\n",
    "        #------------------------------\n",
    "        self.total_scores = 0\n",
    "        self.scores_counts = {}\n",
    "\n",
    "    def append(self, likes):\n",
    "        #append user likes values\n",
    "        self.scores_counts[likes] = self.scores_counts.get(likes,0)+1\n",
    "        self.total_scores +=1\n",
    "\n",
    "    def process(self):\n",
    "        # orders scores and find value ranges\n",
    "        # call before trying to score something\n",
    "        self.processed_already = True\n",
    "        self.keys = list(self.scores_counts.keys())\n",
    "        self.keys.sort()\n",
    "        \n",
    "        partial_count = 0\n",
    "        total_count = sum([count for count in self.scores_counts.values()])\n",
    "        self.stars = {}\n",
    "        for k in self.keys:\n",
    "            self.stars[k] = self.min_star + ((partial_count+0.5*self.scores_counts[k])/total_count)*(self.max_star - self.min_star)\n",
    "            partial_count += self.scores_counts[k]\n",
    "        \n",
    "    def get_star(self, likes):\n",
    "        if likes in self.stars:\n",
    "            return self.stars[likes]\n",
    "        \n",
    "        for k in self.keys:\n",
    "            if k>likes:\n",
    "                return self.stars[k]\n",
    "        return self.max_star\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "880YJ1JS4SP6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "2000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "4000000\n",
      "5000000\n",
      "5000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "8000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "12000000\n",
      "12000000\n",
      "12000000\n",
      "12000000\n",
      "13000000\n",
      "13000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "Processing scores...\n"
     ]
    }
   ],
   "source": [
    "# data_size = 20094655\n",
    "data_size = float(\"inf\")\n",
    "\n",
    "scores = {str(year):Scores() for year in range(2010,2019+1)}\n",
    "i = 0\n",
    "for event, elem in ET.iterparse(\"../raw_dataset/posts_stackoverflow.xml\"):\n",
    "      #Add score if type is question\n",
    "    if elem.tag == \"row\" and event == \"end\" and elem.attrib[\"PostTypeId\"] == \"1\":\n",
    "        year = str(elem.attrib[\"CreationDate\"]).split(\"T\")[0].split(\"-\")[0]\n",
    "        if int(year)>2019:\n",
    "            break\n",
    "        if int(year)>=2010: #2010\n",
    "            scores[year].append(int(elem.attrib[\"Score\"]))\n",
    "            i += 1\n",
    "    elem.clear()\n",
    "    if i % 1000000 == 0 and i>0:\n",
    "        print(i)\n",
    "    if i == data_size:\n",
    "        break\n",
    "\n",
    "# scores.process()\n",
    "print(\"Processing scores...\")\n",
    "for scorer in scores.values():\n",
    "    scorer.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oiGFT_f24YHq"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Scores' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-338e1cd643c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_star\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test other value:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_star\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test other value:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"2019\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_star\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Scores' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "for k in scores[\"2019\"].keys:\n",
    "    print(k,\":\",scores[\"2019\"].scores_counts[k], scores[\"2019\"].get_star(k))\n",
    "\n",
    "print(\"test other value:\", scores[\"2019\"].get_star(1))\n",
    "print(\"test other value:\", scores[\"2019\"].get_star(13000))\n",
    "\n",
    "stars = []\n",
    "for k in scores[\"2019\"].keys:\n",
    "    star = scores[\"2019\"].get_star(k)\n",
    "    for c in range(scores[\"2019\"].scores_counts[k]):\n",
    "        stars.append(star)\n",
    "\n",
    "\n",
    "plt.hist(stars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MpnoQzb-ER14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 questions: 692208\n",
      "total so far: 692208\n",
      "90%, 5%: 622987 34610 \n",
      "\n",
      "2011 questions: 1192677\n",
      "total so far: 1884885\n",
      "90%, 5%: 1696396 94244 \n",
      "\n",
      "2012 questions: 1633858\n",
      "total so far: 3518743\n",
      "90%, 5%: 3166868 175937 \n",
      "\n",
      "2013 questions: 2046718\n",
      "total so far: 5565461\n",
      "90%, 5%: 5008914 278273 \n",
      "\n",
      "2014 questions: 2152753\n",
      "total so far: 7718214\n",
      "90%, 5%: 6946392 385910 \n",
      "\n",
      "2015 questions: 2206658\n",
      "total so far: 9924872\n",
      "90%, 5%: 8932384 496243 \n",
      "\n",
      "2016 questions: 2209585\n",
      "total so far: 12134457\n",
      "90%, 5%: 10921011 606722 \n",
      "\n",
      "2017 questions: 2125712\n",
      "total so far: 14260169\n",
      "90%, 5%: 12834152 713008 \n",
      "\n",
      "2018 questions: 1903069\n",
      "total so far: 16163238\n",
      "90%, 5%: 14546914 808161 \n",
      "\n",
      "2019 questions: 1886778\n",
      "total so far: 18050016\n",
      "90%, 5%: 16245014 902500 \n",
      "\n",
      "total questions: 18050016\n"
     ]
    }
   ],
   "source": [
    "total_questions = 0\n",
    "for key,scorer in scores.items():\n",
    "    year_questions = 0\n",
    "    for val in scorer.scores_counts.values():\n",
    "        year_questions += val\n",
    "    print(key,\"questions:\", year_questions)\n",
    "    total_questions += year_questions\n",
    "    print(\"total so far:\", total_questions)\n",
    "    print(\"90%, 5%:\", str(int(total_questions*0.9)), str(int(total_questions*0.05)), \"\\n\")\n",
    "print(\"total questions:\", total_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XMQyI7CtgVGM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18050\n",
      "18050\n",
      "0\n",
      "18013916\n",
      "18050\n",
      "18050\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data_size = total_questions # 18 050 016\n",
    "data_split = total_questions\n",
    "test_val_percentage = 0.001\n",
    "\n",
    "idx_val = set(random.sample(range(data_split),int(data_split*test_val_percentage)))\n",
    "idx_test = set()\n",
    "for i in range(int(data_split*test_val_percentage)):\n",
    "    n = random.randint(0, data_split-1)\n",
    "    while n in idx_val or n in idx_test:\n",
    "        n = random.randint(0, data_split-1)\n",
    "    idx_test.add(n)\n",
    "print(len(idx_test))\n",
    "print(len(idx_val))\n",
    "print(len(idx_test.intersection(idx_val)))\n",
    "z = np.zeros(data_split)\n",
    "z[list(idx_test)] = 1\n",
    "z[list(idx_val)] = 2\n",
    "print(np.count_nonzero(z == 0))\n",
    "print(np.count_nonzero(z == 1))\n",
    "print(np.count_nonzero(z == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "tpkp1ks7Gg-L",
    "outputId": "07710da0-4c2d-4230-be83-76e96f3fa2c8"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5a661d9888b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdata_writer_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stars\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"tags\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"creation_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#write headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m#Loop to iterate through every element on the XML file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Posts.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;31m#Write row if tag is row and post type is 1 (meaning it is a question)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PostTypeId\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/xml/etree/ElementTree.py\u001b[0m in \u001b[0;36miterparse\u001b[0;34m(source, events, parser)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m         \u001b[0mclose_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Posts.xml'"
     ]
    }
   ],
   "source": [
    "# #Pars XML to CSV (cleaning data)\n",
    "\n",
    "# #Creates list of tags given the string\n",
    "# def createTags(tags):\n",
    "#     return \"|\".join(tags[1:-1].split(\"><\"))\n",
    "\n",
    "# #Clean sentence (remove non alpha chars)\n",
    "# def cleanSentence(sentence):\n",
    "# #     sentence = ''.join([(i.lower() if i.isalpha() else \" \") for i in sentence if i.isalpha() or i == \" \" or i == \"-\"])\n",
    "#     sentence = ''.join([i.lower() if i.isalpha() else \" \" if (i==\" \" or i==\"-\" or i==\"_\") else \"\" for i in sentence])\n",
    "#     return sentence\n",
    "\n",
    "# #Opens CSV file to write parsed rows\n",
    "# i, j = 0, 0\n",
    "# with open('data_stackoverflow_heavy_train.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file:\n",
    "#     with open('data_stackoverflow_heavy_test.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_test:\n",
    "#         with open('data_stackoverflow_heavy_val.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_val:\n",
    "#             #Headers for train\n",
    "#             data_writer = csv.writer(data_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#             data_writer.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "#             #Headers for test\n",
    "#             data_writer_test = csv.writer(data_file_test, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#             data_writer_test.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "#             #Headers for val\n",
    "#             data_writer_val = csv.writer(data_file_val, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#             data_writer_val.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "#             #Loop to iterate through every element on the XML file\n",
    "#             for event, elem in ET.iterparse(\"Posts_stackoverflow.xml\"):\n",
    "#                 #Write row if tag is row and post type is 1 (meaning it is a question)\n",
    "#                 if elem.tag == \"row\" and event == \"end\" and elem.attrib[\"PostTypeId\"] == \"1\":\n",
    "#                     year = str(elem.attrib[\"CreationDate\"]).split(\"T\")[0].split(\"-\")[0]\n",
    "#                     if int(year)>2019:\n",
    "#                         break\n",
    "#                     if int(year)>=2010: # 2010\n",
    "#                         if i % 1 == 0: # i % 18\n",
    "#                             score = int(elem.attrib[\"Score\"])\n",
    "#                             if j in idx_test:\n",
    "#                                 data_writer_test.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"], cleanSentence(elem.attrib[\"Body\"])])\n",
    "#                             elif j in idx_val:\n",
    "#                                 data_writer_val.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])\n",
    "#                             else:\n",
    "#                                 data_writer.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])  \n",
    "#                             j += 1\n",
    "#                     i += 1\n",
    "#                 elem.clear()\n",
    "#                 if i%1000000==0:\n",
    "#                     print(i)\n",
    "#                 if j >= data_split:\n",
    "#                     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "EoZ4GPZQE6JY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "1000000\n",
      "2000000\n",
      "2000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "3000000\n",
      "4000000\n",
      "4000000\n",
      "5000000\n",
      "5000000\n",
      "6000000\n",
      "6000000\n",
      "6000000\n",
      "7000000\n",
      "8000000\n",
      "8000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "9000000\n",
      "10000000\n",
      "11000000\n",
      "11000000\n",
      "11000000\n",
      "11000000\n",
      "12000000\n",
      "13000000\n",
      "13000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "14000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "15000000\n",
      "16000000\n",
      "16000000\n",
      "16000000\n",
      "17000000\n",
      "18000000\n",
      "18000000\n"
     ]
    }
   ],
   "source": [
    "#Pars XML to CSV (cleaning data)\n",
    "# CREATES 3 DATABASES: VAL, TEST, TRAIN_3MOD0, TRAIN_3MOD1, TRAIN_3MOD2\n",
    "\n",
    "#Creates list of tags given the string\n",
    "def createTags(tags):\n",
    "    return \"|\".join(tags[1:-1].split(\"><\"))\n",
    "\n",
    "#Clean sentence (remove non alpha chars)\n",
    "def cleanSentence(sentence):\n",
    "#     sentence = ''.join([(i.lower() if i.isalpha() else \" \") for i in sentence if i.isalpha() or i == \" \" or i == \"-\"])\n",
    "    sentence = ''.join([i.lower() if i.isalpha() else \" \" if (i==\" \" or i==\"-\" or i==\"_\") else \"\" for i in sentence])\n",
    "    return sentence\n",
    "\n",
    "#Opens CSV file to write parsed rows\n",
    "i, j = 0, 0\n",
    "with open('../processed_files/data_stackoverflow_heavy_train_3MOD0.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_train_3MOD0:\n",
    "    with open('../processed_files/data_stackoverflow_heavy_train_3MOD1.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_train_3MOD1:\n",
    "        with open('../processed_files/data_stackoverflow_heavy_train_3MOD2.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_train_3MOD2:\n",
    "            with open('../processed_files/data_stackoverflow_heavy_test.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_test:\n",
    "                with open('../processed_files/data_stackoverflow_heavy_val.csv', mode='w', newline='',encoding=\"utf8\", buffering=1) as data_file_val:\n",
    "                    #Headers for train\n",
    "                    data_writer_train_3MOD0 = csv.writer(data_file_train_3MOD0, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    data_writer_train_3MOD0.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "                    #------------------------------\n",
    "                    data_writer_train_3MOD1 = csv.writer(data_file_train_3MOD1, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    data_writer_train_3MOD1.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "                    #------------------------------\n",
    "                    data_writer_train_3MOD2 = csv.writer(data_file_train_3MOD2, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    data_writer_train_3MOD2.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "                    #------------------------------\n",
    "                    #Headers for test\n",
    "                    data_writer_test = csv.writer(data_file_test, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    data_writer_test.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "                    #------------------------------\n",
    "                    #Headers for val\n",
    "                    data_writer_val = csv.writer(data_file_val, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    data_writer_val.writerow([\"stars\",\"title\",\"tags\",\"score\",\"creation_date\",\"body\"]) #write headers\n",
    "                    #Loop to iterate through every element on the XML file\n",
    "                    for event, elem in ET.iterparse(\"../raw_dataset/posts_stackoverflow.xml\"):\n",
    "                        #Write row if tag is row and post type is 1 (meaning it is a question)\n",
    "                        if elem.tag == \"row\" and event == \"end\" and elem.attrib[\"PostTypeId\"] == \"1\":\n",
    "                            year = str(elem.attrib[\"CreationDate\"]).split(\"T\")[0].split(\"-\")[0]\n",
    "                            if int(year)>2019:\n",
    "                                break\n",
    "                            if int(year)>=2010: # 2010\n",
    "                                if i % 1 == 0: # i % 18\n",
    "                                    score = int(elem.attrib[\"Score\"])\n",
    "                                    if j in idx_test:\n",
    "                                        data_writer_test.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"], cleanSentence(elem.attrib[\"Body\"])])\n",
    "                                    elif j in idx_val:\n",
    "                                        data_writer_val.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])\n",
    "                                    else: #TRAIN\n",
    "                                        if j%3==0:\n",
    "                                            data_writer_train_3MOD0.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])  \n",
    "                                        elif j%3==1:\n",
    "                                            data_writer_train_3MOD1.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])  \n",
    "                                        else:\n",
    "                                            data_writer_train_3MOD2.writerow([scores[year].get_star(score),cleanSentence(elem.attrib[\"Title\"]),createTags(elem.attrib[\"Tags\"].lower()),elem.attrib[\"Score\"],elem.attrib[\"CreationDate\"],cleanSentence(elem.attrib[\"Body\"])])  \n",
    "                                    j += 1\n",
    "                            i += 1\n",
    "                        elem.clear()\n",
    "                        if i%1000000==0:\n",
    "                            print(i)\n",
    "                        if j >= data_split:\n",
    "                            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-QaxRuVxIfgL"
   },
   "outputs": [],
   "source": [
    "total = 0\n",
    "total_true = 0\n",
    "with open(\"../processed_files/data_stackoverflow_train.csv\", \"r\", encoding=\"utf8\") as f:\n",
    "    reader = csv.DictReader(f, delimiter=\",\")\n",
    "    for row in reader:\n",
    "        total += 1\n",
    "        total_true += int(row[\"stars\"])\n",
    "\n",
    "print(\"trues over all on training:\", total_true/total)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "database_creation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
